#### 1.[DL目标检测技术演进（通俗易懂，看一遍能记一辈子！）][Title-0000-01] + 七月在线实验室
Object Detection 主要解决两个问题：位置+分类，即表述为哪里有哪种物体。  
**目前学术和工业界的目标检测方法分为3类**
1. 传统的目标检测算法：`Cascade + HOG/DPM +Haar/SVM`等以及相关改进、融合以及优化
2. 候选窗 + 深度学习分类：`R-CNN(Selective Search + CNN +SVM)`,`SPP-net(ROI Pooling)`,`Fast R-CNN(Selective Search + CNN + ROI)`,`Faster R-CNN(RPN + CNN + ROI)`,`R-FCN`等系列方法；
3. 基于深度学习的回归方法：`YOLO/SSD/DenseBox等`,`结合RNN的RRC detection`,`结合DPM的Deformable CNN等`

几个典型的算法概要：
![img][img-0000-0101]

传统的检测算法流程：  
1. 选择区域(传统方式主要通过穷举策略，即通过滑窗模式，设置不同大小，长宽比进行遍历)
2. 特征提取(SIFT、HOG等，但对于形态，光照，背景等复杂问题常表现为鲁棒性差)
3. 分类器（主要有SVM、Adaboost等）

对于一个物体检测任务而言，可以分解为classification + regression 问题进行分析：  
![img][img-0000-0102]
分类问题还是比较好解决的，关键是对于 regression
比较难以解决，主要是训练参数收敛时间要长很多，所以讲regression问题如何转换为分类问题是当时考虑的一个观点：即通过对产生的滑窗进行分类判别，取其中分类最好的边框作为最后的框（当然考虑NMS，即非极大值抑制）即：
![img][img-0000-0103]  
传统目标的主要问题：
1. 基于滑动窗口的区域的策略没有针对性，时间复杂性搞，窗口冗余
2. 手工设计的特征不具有很好的鲁棒性  

**R-CNN** 横空出世来解决bug啦~~  
通过选择性搜索方式（[[pdf]][pdf-0000-0101]）预先找出 Region Proposal,其中利用图像的纹理、边缘、颜色等信息，使得产生的候选框在较小的窗口仍能保持较高的召回率。当然也有通过EdgeBoxes{TODO}：了解一下。正是建立在region proposal + CNN 框架下，RBG在2014年设计了R-CNN，使得目标检测取得巨大突破  

R-CNN的步骤：
1. 输入测试图像
2. 利用selective search从图像得到 2k 左右的Region Proposal
3. 对取出的候选框进行缩放到 227 * 277 大小并输入到CNN，fc7 作为输出特征
4. 对fc7 输入到SVM 进行分类
?5. 使用回归其精细修正候选框位置，对于每一个类，训练一个线性回归模型去判定这个框是否完美。  
这样处理很慢，因为每一个region proposal 都要进行CNN + SVM是十分耗时的，一张图可能需要 47S。  
![img][img-0000-0104] 

那有没有问题可以解决啊  
答案是有的，从R-CNN处理的方法来看，其实是可以其中在图像上做一次CNN，然后对region proposal的位置映射到特征图上，这样就只需要进行一次CNN。然而对于不同尺度大小的proposal如何处理为一样呢？这里就不得不提Kaiming He等提出的SPP(空间金字塔池化)，即解决了尺寸不归一导致无法全连接输出，也是提议区域的全局内容未经裁剪压缩送到后续处理。（R-CNN为了统一大小，不得不做出裁剪或者压缩）  
这样网络的结构变为：  
![img][img-0000-0105]   

特点：
1. 结合空间金字塔方法实现CNNs的多尺度输入
2. 只对原图提取一次卷积特征   

**Fast R-CNN**  
![img][img-0000-0106]  

在Fast R-CNN上就采纳了SPP net的方法，对其进行了改进。通过对比，可以发现在处理过程有两处不同，一是引入了ROI pooling（即精简版的SPP net，不同的是只对得到layer进行下采样得到`7*7`的feature map，同时vgg16的conv5_3对应512个feature map，即全连接的特征向量为`7*7*512`）;而是损失函数使用了多任务损失函数，将回归问题直接加入到CNN 网络训练(bbox regression 放入训练)  

**Faster R-CNN** wtf，还可以提高？  
推荐[Tensorflow 版本 Faster RCNN 代码解读][link-0000-0101]
是的，还可以改进。其实分析可以发现前两版为了生成较好的候选框，使用了selective search，这个过程是非常耗时的。那能不能找到一个更为高效方式来代替呢?  
Region Proposal Network(RPN),具体怎么操作呢？将RPN放在最后一个卷积层后面，RPN直接训练得到候选区域。  
![img][img-0000-0107]  
{TODO}:理解RPN简介：
1. 在feature map上滑动窗口
2. 建一个神经网络用分类+框位置的回归  
3. 滑动窗口位置提供物体大体位置信息
4. 框的回归提供了框更精确的位置
四个损失函数：  
* RPN calssification(anchor good.bad)
* RPN regression(anchor->propoasal)
* Fast R-CNN classification(over classes)
* Fast R-CNN regression(proposal ->box)  
![img][img-0000-0108]   
![img][img-0000-0109]  



**yolo**  

**SSD**  

**retinaNet**  

**MegNet** 



[Title-0000-01]:https://mp.weixin.qq.com/s/5WLw5Do909KaHsHsagD7WQ
[link-0000-0101]:https://zhuanlan.zhihu.com/p/32230004
[pdf-0000-0101]:http://www.huppelen.nl/publications/selectiveSearchDraft.pdf
[img-0000-0101]:img/20180000-01-01.jpg
[img-0000-0102]:img/20180000-01-02.jpg
[img-0000-0103]:img/20180000-01-03.jpg
[img-0000-0104]:img/20180000-01-04.jpg
[img-0000-0105]:img/20180000-01-05.jpg
[img-0000-0106]:img/20180000-01-06.jpg
[img-0000-0107]:img/20180000-01-07.jpg
[img-0000-0108]:img/20180000-01-08.jpg
[img-0000-0109]:img/20180000-01-09.jpg
