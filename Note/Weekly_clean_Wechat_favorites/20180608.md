
#### 1.[从YOLOv1到YOLOv3，目标检测的进化之路][Title-0608-01] + AI科技大本营

> yolo 的核心思想在于通过将图片分成 S*S 网格进行回归预测bounding box 的位置和所属类别
* YOLO  
直接在卷积网络全连接层后面一次全连接，后对连接层进行 reshape 到 (S,S,B*5+C) 用来对边界框进行回归预测。强烈推荐观看该[PPT][PPT-0608-0101] 学习yolo的整个运行流程,讲解的非常的清楚。  
整体的损失函数描述：  
![img-0608-01-01][img-0608-01-01]
一些问题：
	* localization error 和 classification· error的权值不应该同等
	* 若网格没有object，则应当将网络的 box 的 confidence push 到0
解决方法：
	* coord 权值设为5，noobje 设为0.5，confidence loss 和 weight loss 设为1
	* 对于大小框偏移 loss 不应当同等看待的问题，作者采用将 box 的width 和 height 采用平方根的形式。

1. YOLO 对相互靠的很近的物体，还有很小的群体检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类。
2. 同一类物体出现的新的不常见的长宽比和其他情况时，泛化能力偏弱。
3. 由于损失函数的问题，定位误差是影响检测效果的主要原因。尤其是大小物体的处理上，还有待加强。

* YOLOv2
> 代表着目前业界最先进物体检测水平，他的速度也是毋庸置疑的快，且YOLO9000 这个网络可以实时检测超过 9000 类物体，这归功于使用了 WordTree。  

YOLOv2里面的小trick：
* trick
	* Batch Normalization：每一个卷积层增加了批次归一化，使得mAP提高了2%，使用了BN，去掉了Dropout
	* High resolution classifier：工业界普遍用的是 256*256，而现在YOLOv2将分辨率从224*224 提高到448*448，具体做法是先在448*448分辨率在ImageNet进行微调，调优用于检测的Resulting Network，使得mAP提升了4%
	* Convolution with anchor boxes：YOLO最开始版本使用的是全连接层去直接预测Bounding Boxes的坐标值。YOLOv2则去掉最后连接层，通过32下采样，对于416的图片得到输出的13*13 的feature map。使用anchor box会使得精确度稍微下降，但用它可以让YOLO预测上千个框，同时recall达到 88%，mAP达到69.2%
	* Dimension clusters：这算是YOLOv2上一个比较好的设计内容，通过k-mean聚类真实框分布，从而找到一个较好的值进行迭代
	* Direct location prediction：对于使用Anchor Box会使得model变得不稳定，主要是参数x，y位置不稳定，为了保证其预测稳定，通过Logistic Activation使得预测结果在0-1之间。通过使用`Dimension clusters` 和 `Direct location prediction` 其效果比其他使用anchor box 提高了近 5%。
	* Fine-Grained Features：YOLOv2加上了一个Passthrough layer 去得26*26分辨率的特征，用来取得一些细粒度的特征信息
	* Multi-Scale Training:网络自动修改尺寸，继续训练。其尺度迭代每10个Batch更改一个（320,352，...608）
相比之前的版本，通过使用GoogLeNet架构，计算次数从306.9亿次降低到85.2亿次，虽然精度有所下降。  
{TODO}:理解Hierarchical classification  
![img][img-0608-01-02]

* YOLOv3   
> YOLOv3 的模型相比之前的复杂了不少，可以通过改变模型结构大小来权衡速度与精度。{TODO}:简而言之，YOLOv3 的先验检测（Prior detection）系统将分类器或定位器重新用于执行检测任务。他们将模型应用于图像的多个位置和尺度。而那些评分较高的区域就可以视为检测结果。此外，相对于其它目标检测方法，我们使用了完全不同的方法。我们将一个单神经网络应用于整张图像，该网络将图像划分为不同的区域，因而预测每一块区域的边界框和概率，这些边界框会通过预测的概率加权。我们的模型相比于基于分类器的系统有一些优势。它在测试时会查看整个图像，所以它的预测利用了图像中的全局信息。与需要数千张单一目标图像的 R-CNN 不同，它通过单一网络评估进行预测。这令 YOLOv3 非常快，一般它比 R-CNN 快 1000 倍、比 Fast R-CNN 快 100 倍。  


* 改进地方：
	* 多尺度（三个）预测三个box（类FPN）
	* 使用了类ResNet的分类网络
	* 分类器-类别预测，不适用Softmax对框进行预测
YOLOv3的结构：  
![img][img-0608-01-03]  
YOLOv3 在 mAP@0.5 及小目标 APs 上具有不错的结果，但随着 IOU的增大，性能下降，说明 YOLOv3 不能很好地与 ground truth 切合.  

YOLOv3 输入416*416 整个网络流程（使用keras生成）
![img](img/yolov3-416.png)




---
[Title-0608-01]:https://mp.weixin.qq.com/s/f27A3hfXgGx0b24_5mKryw
[img-0608-01-01]:img/20180608-01-01.jpg
[img-0608-01-02]:img/20180608-01-02.jpg
[img-0608-01-03]:img/20180608-01-03.jpg
[PPT-0608-0101]:https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p
