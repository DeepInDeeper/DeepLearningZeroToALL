{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 使用gluon 进行冰川识别\n",
    "kaggle 冰川比赛[链接](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from subprocess import check_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据，并显示数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:/dataset/kaggle_Iceberg/'\n",
    "train_path = data_path + \"train.json\"\n",
    "test_path  = data_path + \"test.json\"\n",
    "train_json = pd.read_json(train_path)\n",
    "test_json = pd.read_json(test_path)\n",
    "train_json['inc_angle'] = pd.to_numeric(train_json['inc_angle'], errors='coerce')\n",
    "test_json['inc_angle'] = pd.to_numeric(test_json['inc_angle'], errors='coerce')\n",
    "print (len(train_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878361, -27.15416, -28.668615, -29.537971...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920305, -14.920363, -12.66633...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              band_1  \\\n",
       "0  [-27.878361, -27.15416, -28.668615, -29.537971...   \n",
       "1  [-12.242375, -14.920305, -14.920363, -12.66633...   \n",
       "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2        id  inc_angle  \\\n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913    43.9239   \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd    38.1562   \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0    45.2859   \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18    43.8306   \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4    35.6256   \n",
       "\n",
       "   is_iceberg  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train Records\")\n",
    "train_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-15.863251, -15.201077, -17.887735, -19.17248...</td>\n",
       "      <td>[-21.629612, -21.142353, -23.908337, -28.34524...</td>\n",
       "      <td>5941774d</td>\n",
       "      <td>34.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-26.0589694977, -26.0589694977, -26.058969497...</td>\n",
       "      <td>[-25.7542076111, -25.7542076111, -25.754207611...</td>\n",
       "      <td>4023181e</td>\n",
       "      <td>32.615072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-14.1410999298, -15.0642414093, -17.375520706...</td>\n",
       "      <td>[-14.745639801, -14.5904102325, -14.3626976013...</td>\n",
       "      <td>b20200e4</td>\n",
       "      <td>37.505433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-12.167478, -13.706167, -16.54837, -13.572674...</td>\n",
       "      <td>[-24.32222, -26.375538, -24.096739, -23.8769, ...</td>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>34.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-23.3745937347, -26.0271816254, -28.121963501...</td>\n",
       "      <td>[-25.7223434448, -27.0115776062, -23.149162292...</td>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>43.918874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              band_1  \\\n",
       "0  [-15.863251, -15.201077, -17.887735, -19.17248...   \n",
       "1  [-26.0589694977, -26.0589694977, -26.058969497...   \n",
       "2  [-14.1410999298, -15.0642414093, -17.375520706...   \n",
       "3  [-12.167478, -13.706167, -16.54837, -13.572674...   \n",
       "4  [-23.3745937347, -26.0271816254, -28.121963501...   \n",
       "\n",
       "                                              band_2        id  inc_angle  \n",
       "0  [-21.629612, -21.142353, -23.908337, -28.34524...  5941774d  34.966400  \n",
       "1  [-25.7542076111, -25.7542076111, -25.754207611...  4023181e  32.615072  \n",
       "2  [-14.745639801, -14.5904102325, -14.3626976013...  b20200e4  37.505433  \n",
       "3  [-24.32222, -26.375538, -24.096739, -23.8769, ...  e7f018bb  34.473900  \n",
       "4  [-25.7223434448, -27.0115776062, -23.149162292...  4371c8c3  43.918874  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test Records\")\n",
    "test_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强部分\n",
    "这里使用了skimage进行图像处理  \n",
    "对训练数据进行随机裁剪和镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "# Isolation function.\n",
    "def iso(arr):\n",
    "    image = img_as_float(np.reshape(np.array(arr), [75,75]))\n",
    "    image = gaussian_filter(image,2)\n",
    "    seed = np.copy(image)\n",
    "    seed[1:-1, 1:-1] = image.min()\n",
    "    mask = image \n",
    "    dilated = reconstruction(seed, mask, method='dilation')\n",
    "    return image-dilated\n",
    "\n",
    "# Feature engineering iso1 and iso2.\n",
    "train_json['iso1'] = train_json.iloc[:, 0].apply(iso)\n",
    "train_json['iso2'] = train_json.iloc[:, 1].apply(iso)\n",
    "\n",
    "test_json['iso1'] = test_json.iloc[:, 0].apply(iso)\n",
    "test_json['iso2'] = test_json.iloc[:, 1].apply(iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "\n",
    "def data_norm(data):\n",
    "    images = []\n",
    "    for i,row in data.iterrows():\n",
    "        band_1 = np.reshape(np.array(row[\"iso1\"]).astype(np.float32),(75,75))\n",
    "        band_2 = np.reshape(np.array(row[\"iso2\"]).astype(np.float32),(75,75))\n",
    "        band_3 = (band_1+band_2)/2\n",
    "\n",
    "        band_1_norm = band_1/ band_1.max() \n",
    "        band_2_norm = band_2 / band_2.max()\n",
    "        band_3_norm = band_3 / band_3.max() \n",
    "        images.append(np.stack((band_1,band_2,band_3)))\n",
    "    return np.array(images)\n",
    "\n",
    "def transform_train(data):\n",
    "    data = nd.array(data)\n",
    "    #data = (data-data.min())/(data.max()-data.min())\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 75, 75), resize=0, \n",
    "                        rand_crop=True, rand_resize=True, rand_mirror=True,\n",
    "                        brightness=0, contrast=0, \n",
    "                        saturation=0, hue=0, \n",
    "                        pca_noise=0, rand_gray=0, inter_method=2)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        im = data[i,:]\n",
    "        for aug in auglist:\n",
    "            data[i,:] = aug(data[i,:])\n",
    "    return data.asnumpy()\n",
    "\n",
    "def transform_test(data):\n",
    "    data = nd.array(data)\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 75, 75))\n",
    "    for i in range(data.shape[0]):\n",
    "        for aug in auglist:\n",
    "            data[i,:] = aug(data[i,:])\n",
    "    return data.asnumpy()\n",
    "\n",
    "def aug_img (data,aug_method):\n",
    "    dataset = data_norm(data)\n",
    "    dataset = np.transpose(dataset, (0,3,2,1))\n",
    "    if aug_method == \"train\":\n",
    "        dataset = transform_train(dataset) \n",
    "    elif aug_method == \"test\":\n",
    "        dataset = transform_test(dataset)\n",
    "    dataset = np.transpose(dataset, (0,3,2,1))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_total = aug_img(train_json,\"train\")\n",
    "X_train_total = data_norm(train_json)\n",
    "y_train_total = np.array(train_json['is_iceberg'])\n",
    "X_angle_train_total = np.array(train_json.inc_angle)\n",
    "\n",
    "# X_test = aug_img(test_json,\"test\")\n",
    "X_test = data_norm(test_json)\n",
    "X_angle_test = np.array(test_json.inc_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604L, 3L, 75L, 75L)\n",
      "(0.0, 32.082642)\n"
     ]
    }
   ],
   "source": [
    "print X_train_total.shape\n",
    "print (X_train_total.min(),X_train_total.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train_total\n",
    "                    , X_angle_train_total, y_train_total, random_state=123, test_size=0.1)\n",
    "\n",
    "    \n",
    "\n",
    "y_test = np.zeros((X_test.shape[0],), dtype=np.int)\n",
    "\n",
    "train_ds = gluon.data.ArrayDataset(X_train, y_train)\n",
    "valid_ds = gluon.data.ArrayDataset(X_valid, y_valid)\n",
    "train_valid_ds = gluon.data.ArrayDataset(X_train_total,y_train_total)\n",
    "test_ds = gluon.data.ArrayDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443L, 3L, 75L, 75L)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data= loader(train_valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "test_data = loader(test_ds,batch_size,shuffle = True,last_batch='keep')\n",
    "# 交叉熵损失函数。\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "from mxnet import init\n",
    "\n",
    "## model\n",
    "class Conv(nn.HybridBlock):\n",
    "    \"\"\"docstring for Conv\"\"\"\n",
    "    def __init__(self, channels,kernel_size,pool_size,strides,dropout):\n",
    "        super(Conv, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.conv = nn.Conv2D(channels,kernel_size=kernel_size,activation=\"relu\")\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.pool = nn.MaxPool2D(pool_size=pool_size,strides=strides)\n",
    "            self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def hybrid_forward(self,F,x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.drop(out)\n",
    "        return out\n",
    "\n",
    "class MyModel(nn.HybridBlock):\n",
    "    \"\"\"docstring for MyModel\"\"\"\n",
    "    def __init__(self,num_outputs,verbose=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.verbose = verbose\n",
    "            net = self.net = nn.HybridSequential()\n",
    "\n",
    "            net.add(Conv(channels=8,kernel_size=3,pool_size=3,strides=2,dropout=0.2))\n",
    "            net.add(Conv(channels=16,kernel_size=3,pool_size=2,strides=2,dropout=0.2))\n",
    "            net.add(Conv(channels=32,kernel_size=3,pool_size=2,strides=2,dropout=0.3))\n",
    "            net.add(Conv(channels=64,kernel_size=3,pool_size=2,strides=2,dropout=0.3))\n",
    "\n",
    "            net.add(nn.Flatten())\n",
    "            net.add(nn.Dense(512))\n",
    "            net.add(nn.Dropout(0.2))\n",
    "            net.add(nn.Dense(256))\n",
    "            net.add(nn.Dropout(0.5))\n",
    "            net.add(nn.Dense(num_outputs))\n",
    "    def hybrid_forward(self,F,x):\n",
    "        out = x\n",
    "        for i,b in enumerate(self.net):\n",
    "            out = b(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d output: %s'%(i+1, out.shape))\n",
    "        return out\n",
    "\n",
    "def net_init(ctx):\n",
    "    num_outputs = 2\n",
    "    net = MyModel(num_outputs)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 output: (4L, 8L, 36L, 36L)\n",
      "Block 2 output: (4L, 16L, 17L, 17L)\n",
      "Block 3 output: (4L, 32L, 7L, 7L)\n",
      "Block 4 output: (4L, 64L, 2L, 2L)\n",
      "Block 5 output: (4L, 256L)\n",
      "Block 6 output: (4L, 512L)\n",
      "Block 7 output: (4L, 512L)\n",
      "Block 8 output: (4L, 256L)\n",
      "Block 9 output: (4L, 256L)\n",
      "Block 10 output: (4L, 2L)\n"
     ]
    }
   ],
   "source": [
    "net = MyModel(2, verbose=True)\n",
    "net.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(4, 3, 75, 75))\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_loss(data, net, ctx):\n",
    "    loss = 0.0\n",
    "    for feas, label in data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(feas.as_in_context(ctx))\n",
    "        cross_entropy = softmax_cross_entropy(output, label)\n",
    "        loss += nd.mean(cross_entropy).asscalar()\n",
    "    return loss / len(data)\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period,\n",
    "          lr_decay):\n",
    "    loss = 10\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9,\n",
    "                                      'wd': wd})\n",
    "    prev_time = datetime.datetime.now()\n",
    "    plt_train_loss = []\n",
    "    plt_valid_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        if epoch < 200 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "#         if epoch > 81 and epoch % 10 == 0:\n",
    "#             trainer.set_learning_rate(trainer.learning_rate * 0.1)\n",
    "        for data, label in train_data:\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
    "                         % (epoch, train_loss / len(train_data), valid_loss))\n",
    "            plt_train_loss.append(train_loss / len(train_data))\n",
    "            plt_valid_loss.append(valid_loss)\n",
    "            \n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
    "                         % (epoch, train_loss / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        if epoch % 10==0:\n",
    "            print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "\n",
    "    # plot \n",
    "    if valid_data is not None:\n",
    "        plt.plot(plt_train_loss)\n",
    "        plt.plot(plt_valid_loss)\n",
    "        plt.legend(['train_loss','test_loss'])\n",
    "        plt.savefig(\"Loss22.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train loss: 1.838184, Valid loss 0.748394, Time 00:00:02, lr 0.0005\n",
      "Epoch 10. Train loss: 0.668044, Valid loss 0.625701, Time 00:00:00, lr 0.0005\n",
      "Epoch 20. Train loss: 0.537986, Valid loss 0.851179, Time 00:00:00, lr 0.0005\n",
      "Epoch 30. Train loss: 0.511858, Valid loss 0.761613, Time 00:00:00, lr 0.0005\n",
      "Epoch 40. Train loss: 0.446770, Valid loss 0.874131, Time 00:00:00, lr 0.0005\n",
      "Epoch 50. Train loss: 0.431827, Valid loss 0.686214, Time 00:00:00, lr 0.0005\n",
      "Epoch 60. Train loss: 0.382938, Valid loss 0.793766, Time 00:00:00, lr 0.0005\n",
      "Epoch 70. Train loss: 0.423200, Valid loss 0.996644, Time 00:00:00, lr 0.0005\n",
      "Epoch 80. Train loss: 0.387688, Valid loss 1.003483, Time 00:00:00, lr 0.0005\n",
      "Epoch 90. Train loss: 0.349298, Valid loss 0.960741, Time 00:00:00, lr 0.0005\n"
     ]
    }
   ],
   "source": [
    "from mynet import *\n",
    "ctx = utils.try_gpu()\n",
    "num_epochs = 300\n",
    "learning_rate = 0.005\n",
    "weight_decay = 5e-5\n",
    "lr_period = 200\n",
    "lr_decay = .1\n",
    "\n",
    "# net = get_simple_net(ctx)\n",
    "#net = net_init(ctx)\n",
    "net = get_simple_net(ctx,\"mymode\")\n",
    "#net  = vgg_net(ctx)\n",
    "net.hybridize()\n",
    "train(net, train_data, valid_data, num_epochs, learning_rate,weight_decay, ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "net = get_simple_net(ctx,\"mymode\")\n",
    "net.hybridize()\n",
    "train(net, train_valid_data, None, num_epochs, learning_rate, weight_decay,\n",
    "      ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用训练好的模型对测试样本进行预测，并保存文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for data, label in test_data:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx)))\n",
    "    outputs.extend(output.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pre = []\n",
    "\n",
    "for num in outputs:\n",
    "    test_pre.append(num[1])\n",
    "print (len(test_pre)==8424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_json[\"id\"], 'is_iceberg': test_pre})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
