{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 使用gluon 进行冰川识别\n",
    "kaggle 冰川比赛[链接](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from subprocess import check_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据，并显示数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:/dataset/kaggle_Iceberg/'\n",
    "train_path = data_path + \"train.json\"\n",
    "test_path  = data_path + \"test.json\"\n",
    "train_json = pd.read_json(train_path)\n",
    "test_json = pd.read_json(test_path)\n",
    "train_json['inc_angle'] = pd.to_numeric(train_json['inc_angle'], errors='coerce')\n",
    "test_json['inc_angle'] = pd.to_numeric(test_json['inc_angle'], errors='coerce')\n",
    "print (len(train_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Records\")\n",
    "train_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Records\")\n",
    "test_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强部分\n",
    "对训练数据进行随机裁剪和镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "\n",
    "def data_norm(data):\n",
    "    images = []\n",
    "    for i,row in data.iterrows():\n",
    "        band_1 = np.reshape(np.array(row[\"band_1\"]).astype(np.float32),(75,75))\n",
    "        band_2 = np.reshape(np.array(row[\"band_2\"]).astype(np.float32),(75,75))\n",
    "        band_3 = band_1+band_2\n",
    "\n",
    "        band_1_norm = (band_1-band_1.mean())/ (band_1.max() - band_1.min())\n",
    "        band_2_norm = (band_2-band_2.mean() ) / (band_2.max() - band_2.min())\n",
    "        band_3_norm = (band_3 -band_3.mean()) / (band_3.max() - band_3.min())\n",
    "        images.append(np.stack((band_1_norm,band_2_norm,band_3_norm)))\n",
    "    return np.array(images)\n",
    "\n",
    "def transform_train(data):\n",
    "    data = nd.array(data)\n",
    "    #data = (data-data.min())/(data.max()-data.min())\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 75, 75), resize=0, \n",
    "                        rand_crop=True, rand_resize=True, rand_mirror=True,\n",
    "                        brightness=0, contrast=0, \n",
    "                        saturation=0, hue=0, \n",
    "                        pca_noise=0, rand_gray=0, inter_method=2)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        im = data[i,:]\n",
    "        for aug in auglist:\n",
    "            data[i,:] = aug(data[i,:])\n",
    "    return data.asnumpy()\n",
    "\n",
    "def transform_test(data):\n",
    "    data = nd.array(data)\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 75, 75))\n",
    "    for i in range(data.shape[0]):\n",
    "        for aug in auglist:\n",
    "            data[i,:] = aug(data[i,:])\n",
    "    return data.asnumpy()\n",
    "\n",
    "def aug_img (data,aug_method):\n",
    "    dataset = data_norm(data)\n",
    "    dataset = np.transpose(dataset, (0,3,2,1))\n",
    "    if aug_method == \"train\":\n",
    "        dataset = transform_train(dataset) \n",
    "    elif aug_method == \"test\":\n",
    "        dataset = transform_test(dataset)\n",
    "    dataset = np.transpose(dataset, (0,3,2,1))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_total = aug_img(train_json,\"train\")\n",
    "y_train_total = np.array(train_json['is_iceberg'])\n",
    "X_angle_train_total = np.array(train_json.inc_angle)\n",
    "\n",
    "X_test = aug_img(test_json,\"test\")\n",
    "X_angle_test = np.array(test_json.inc_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X_train_total.shape\n",
    "# X_hah = data_norm(train_json)\n",
    "# print (X_hah.max(),X_hah.min())\n",
    "# img = X_train_total[10,:]\n",
    "# img = np.transpose(img,(2,1,0))\n",
    "# print img.max(),img.min()\n",
    "# fig = plt.figure(1,figsize=(15,15))\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "# ax.imshow(img)\n",
    "\n",
    "print (X_train_total.min(),X_train_total.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train_total\n",
    "                    , X_angle_train_total, y_train_total, random_state=123, test_size=0.1)\n",
    "\n",
    "    \n",
    "\n",
    "y_test = np.zeros((X_test.shape[0],), dtype=np.int)\n",
    "\n",
    "train_ds = gluon.data.ArrayDataset(X_train, y_train)\n",
    "valid_ds = gluon.data.ArrayDataset(X_valid, y_valid)\n",
    "train_valid_ds = gluon.data.ArrayDataset(X_train_total,y_train_total)\n",
    "test_ds = gluon.data.ArrayDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data= loader(train_valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "test_data = loader(test_ds,batch_size,shuffle = True,last_batch='keep')\n",
    "# 交叉熵损失函数。\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演示数据在块之间的形状变化\n",
    "采用不同的net的形状变化 在这里进行显示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mynet import * \n",
    "from vggnet import *\n",
    "\n",
    "net = VggNet(2, verbose=True)\n",
    "net.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(4, 3, 75, 75))\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_loss(data, net, ctx):\n",
    "    loss = 0.0\n",
    "    for feas, label in data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(feas.as_in_context(ctx))\n",
    "        cross_entropy = softmax_cross_entropy(output, label)\n",
    "        loss += nd.mean(cross_entropy).asscalar()\n",
    "    return loss / len(data)\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period,\n",
    "          lr_decay):\n",
    "    loss = 10\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9,\n",
    "                                      'wd': wd})\n",
    "    prev_time = datetime.datetime.now()\n",
    "    plt_train_loss = []\n",
    "    plt_valid_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        if epoch < 81 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        if epoch > 81 and epoch % 10 == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * 0.1)\n",
    "        for data, label in train_data:\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
    "                         % (epoch, train_loss / len(train_data), valid_loss))\n",
    "            plt_train_loss.append(train_loss / len(train_data))\n",
    "            plt_valid_loss.append(valid_loss)\n",
    "            \n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
    "                         % (epoch, train_loss / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        if epoch % 10==0:\n",
    "            print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "\n",
    "    # plot \n",
    "    if valid_data is not None:\n",
    "        plt.plot(plt_train_loss)\n",
    "        plt.plot(plt_valid_loss)\n",
    "        plt.legend(['train_loss','test_loss'])\n",
    "        plt.savefig(\"Loss22.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = utils.try_gpu()\n",
    "num_epochs = 140\n",
    "learning_rate = 0.01\n",
    "weight_decay = 5e-4\n",
    "lr_period = 100\n",
    "lr_decay = 0.1\n",
    "\n",
    "# net = get_simple_net(ctx)\n",
    "#net = get_simple_net(ctx,\"resnet\")\n",
    "net  = vgg_net(ctx)\n",
    "net.hybridize()\n",
    "train(net, train_data, valid_data, num_epochs, learning_rate,weight_decay, ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "net = get_simple_net(ctx)\n",
    "net.hybridize()\n",
    "train(net, train_valid_data, None, num_epochs, learning_rate, weight_decay,\n",
    "      ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用训练好的模型对测试样本进行预测，并保存文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for data, label in test_data:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx)))\n",
    "    outputs.extend(output.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pre = []\n",
    "\n",
    "for num in outputs:\n",
    "    test_pre.append(num[1])\n",
    "print (len(test_pre)==8424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_json[\"id\"], 'is_iceberg': test_pre})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
