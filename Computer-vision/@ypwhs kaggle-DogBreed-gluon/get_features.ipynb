{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mxnet.incubator.apache.org/api/python/image/image.html\n",
    "* http://zh.gluon.ai/chapter_computer-vision/fine-tuning.html\n",
    "* http://zh.gluon.ai/chapter_computer-vision/kaggle-gluon-dog.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "\n",
    "preprocessing = [\n",
    "    image.ForceResizeAug((224,224)),\n",
    "    image.ColorNormalizeAug(mean=nd.array([0.485, 0.456, 0.406]), std=nd.array([0.229, 0.224, 0.225]))\n",
    "]\n",
    "\n",
    "def transform(data, label):\n",
    "    data = data.astype('float32') / 255\n",
    "    for pre in preprocessing:\n",
    "        data = pre(data)\n",
    "    \n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, nd.array([label]).asscalar().astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义导出特征向量的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(net, data):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for X, y in tqdm(data):\n",
    "        feature = net.features(X.as_in_context(ctx))\n",
    "        features.append(feature.asnumpy())\n",
    "        labels.append(y.asnumpy())\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mxnet.incubator.apache.org/versions/master/api/python/gluon/model_zoo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导出训练集和测试集的特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [03:05<00:00,  1.41s/it]\n",
      "100%|██████████| 594/594 [04:25<00:00,  3.35s/it]\n",
      "100%|██████████| 594/594 [07:36<00:00,  7.98s/it]\n"
     ]
    }
   ],
   "source": [
    "preprocessing[0] = image.ForceResizeAug((224,224))\n",
    "imgs = vision.ImageFolderDataset('D:/dataset/dogbreed/train_valid_test/train/', transform=transform)\n",
    "data = gluon.data.DataLoader(imgs, 16)\n",
    "\n",
    "features_vgg, labels = get_features(models.vgg16_bn(pretrained=True, ctx=ctx), data)\n",
    "features_resnet, _ = get_features(models.resnet152_v1(pretrained=True, ctx=ctx), data)\n",
    "features_densenet, _ = get_features(models.densenet161(pretrained=True, ctx=ctx), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [03:36<00:00,  4.81s/it]\n"
     ]
    }
   ],
   "source": [
    "preprocessing[0] = image.ForceResizeAug((299,299))\n",
    "imgs_299 = vision.ImageFolderDataset('D:/dataset/dogbreed/train_valid_test/train/', transform=transform)\n",
    "data_299 = gluon.data.DataLoader(imgs_299, 16)\n",
    "\n",
    "features_inception, _ = get_features(models.inception_v3(pretrained=True, ctx=ctx), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('features.h5', 'w') as f:\n",
    "    f['vgg'] = features_vgg\n",
    "    f['resnet'] = features_resnet\n",
    "    f['densenet'] = features_densenet\n",
    "    f['inception'] = features_inception\n",
    "    f['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648/648 [13:07<00:00,  7.31s/it]\n",
      "100%|██████████| 648/648 [04:38<00:00,  1.55s/it]\n",
      "100%|██████████| 648/648 [08:09<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "preprocessing[0] = image.ForceResizeAug((224,224))\n",
    "imgs = vision.ImageFolderDataset('D:/dataset/dogbreed/train_valid_test/test/', transform=transform)\n",
    "data = gluon.data.DataLoader(imgs, 16)\n",
    "\n",
    "features_vgg, _ = get_features(models.vgg16_bn(pretrained=True, ctx=ctx), data)\n",
    "features_resnet, _ = get_features(models.resnet152_v1(pretrained=True, ctx=ctx), data)\n",
    "features_densenet, _ = get_features(models.densenet161(pretrained=True, ctx=ctx), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648/648 [03:30<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "preprocessing[0] = image.ForceResizeAug((299,299))\n",
    "imgs_299 = vision.ImageFolderDataset('D:/dataset/dogbreed/train_valid_test/test/', transform=transform)\n",
    "data_299 = gluon.data.DataLoader(imgs_299, 16)\n",
    "\n",
    "features_inception, _ = get_features(models.inception_v3(pretrained=True, ctx=ctx), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('features_test.h5', 'w') as f:\n",
    "    f['vgg'] = features_vgg\n",
    "    f['resnet'] = features_resnet\n",
    "    f['densenet'] = features_densenet\n",
    "    f['inception'] = features_inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
